{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00122289-7b83-4c75-b6dc-d7e63239e3e1",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470f9ccd-7540-423a-bdba-768f07caddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edilson07/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0269e56d-a305-4eae-a27f-58c09efef935",
   "metadata": {},
   "source": [
    "# 1.Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4d9a59-2184-4e45-880d-5c4c60837fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path, max_rows=100000):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    if i >= max_rows:\n",
    "        break\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df_raw = getDF('/home/edilson07/projects/sentiment_analysis/Electronics_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245b5543-52cf-492f-a263-1f4690dcf347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 1999</td>\n",
       "      <td>AAP7PPBU72QFM</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>D. C. Carrad</td>\n",
       "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "      <td>937612800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 23, 2013</td>\n",
       "      <td>A2E168DTVGE6SV</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>Evy</td>\n",
       "      <td>Pages and pages of introspection, in the style...</td>\n",
       "      <td>A stream of consciousness novel</td>\n",
       "      <td>1382486400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>09 2, 2008</td>\n",
       "      <td>A1ER5AYS3FQ9O3</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Paperback'}</td>\n",
       "      <td>Kcorn</td>\n",
       "      <td>This is the kind of novel to read when you hav...</td>\n",
       "      <td>I'm a huge fan of the author and this one did ...</td>\n",
       "      <td>1220313600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>09 4, 2000</td>\n",
       "      <td>A1T17LMQABMBN5</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>Caf Girl Writes</td>\n",
       "      <td>What gorgeous language! What an incredible wri...</td>\n",
       "      <td>The most beautiful book I have ever read!</td>\n",
       "      <td>968025600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2000</td>\n",
       "      <td>A3QHJ0FXK33OBE</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>W. Shane Schmidt</td>\n",
       "      <td>I was taken in by reviews that compared this b...</td>\n",
       "      <td>A dissenting view--In part.</td>\n",
       "      <td>949622400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM  0151004714   \n",
       "1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV  0151004714   \n",
       "2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3  0151004714   \n",
       "3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5  0151004714   \n",
       "4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE  0151004714   \n",
       "\n",
       "                            style      reviewerName  \\\n",
       "0       {'Format:': ' Hardcover'}      D. C. Carrad   \n",
       "1  {'Format:': ' Kindle Edition'}               Evy   \n",
       "2       {'Format:': ' Paperback'}             Kcorn   \n",
       "3       {'Format:': ' Hardcover'}   Caf Girl Writes   \n",
       "4       {'Format:': ' Hardcover'}  W. Shane Schmidt   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  This is the best novel I have read in 2 or 3 y...   \n",
       "1  Pages and pages of introspection, in the style...   \n",
       "2  This is the kind of novel to read when you hav...   \n",
       "3  What gorgeous language! What an incredible wri...   \n",
       "4  I was taken in by reviews that compared this b...   \n",
       "\n",
       "                                             summary  unixReviewTime image  \n",
       "0                                     A star is born       937612800   NaN  \n",
       "1                    A stream of consciousness novel      1382486400   NaN  \n",
       "2  I'm a huge fan of the author and this one did ...      1220313600   NaN  \n",
       "3          The most beautiful book I have ever read!       968025600   NaN  \n",
       "4                        A dissenting view--In part.       949622400   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc93187-021a-4d63-abe2-7c2273478a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranin Test Split\n",
    "df_raw, X_test = train_test_split(df_raw, test_size=0.2, random_state=42, stratify=df_raw['overall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9edf1e4-c958-4c09-adba-82132c47a0e1",
   "metadata": {},
   "source": [
    "## 0.2 Drop Unecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "828e29aa-77e9-4c96-9afc-e184a39046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_select = ['overall','reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf41581-e579-405d-8c1f-5bc1d46148fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw[cols_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e84dbbc-db1d-4476-b1a4-961fe547eae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82935</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Does what it is supposed to do....the screen r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54402</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Defective out of the box. As with other custom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80729</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great little radio. Well made and works well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>4.0</td>\n",
       "      <td>The description of the book is right-on and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95092</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Works good!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall                                         reviewText\n",
       "82935      5.0  Does what it is supposed to do....the screen r...\n",
       "54402      1.0  Defective out of the box. As with other custom...\n",
       "80729      5.0      Great little radio. Well made and works well.\n",
       "1797       4.0  The description of the book is right-on and th...\n",
       "95092      5.0                                        Works good!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694d025-7b95-475b-864b-e50614df06f6",
   "metadata": {},
   "source": [
    "# 1.0 Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88f5ef5-add1-4c4e-bd4c-13e3cbca5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecab5099-7b44-4391-b70a-7f6a5095f566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edilson07/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/edilson07/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/edilson07/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='overall', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df, x='overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a2e4542-cedc-4669-8f34-5501bde3e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = {\n",
    "    5.0 : 'Very Positive',\n",
    "    4.0 : 'Positive',\n",
    "    3.0 : 'Neutral',\n",
    "    2.0 : 'Negative',\n",
    "    1.0 : 'Negative'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ded67dec-6406-4553-9492-aa91e1f30d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overall'] = df['overall'].map(sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e689ad82-4602-492f-b8d9-8aaa236ddf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82935</th>\n",
       "      <td>Very Positive</td>\n",
       "      <td>Does what it is supposed to do....the screen r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54402</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Defective out of the box. As with other custom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80729</th>\n",
       "      <td>Very Positive</td>\n",
       "      <td>Great little radio. Well made and works well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>Positive</td>\n",
       "      <td>The description of the book is right-on and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95092</th>\n",
       "      <td>Very Positive</td>\n",
       "      <td>Works good!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             overall                                         reviewText\n",
       "82935  Very Positive  Does what it is supposed to do....the screen r...\n",
       "54402       Negative  Defective out of the box. As with other custom...\n",
       "80729  Very Positive      Great little radio. Well made and works well.\n",
       "1797        Positive  The description of the book is right-on and th...\n",
       "95092  Very Positive                                        Works good!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63fc13-eebe-4199-86ea-2aada60b68fc",
   "metadata": {},
   "source": [
    "## 1.2 NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f49787c4-e60f-4fcb-b0b0-5346d571b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c0d85c-95f6-4389-9775-8e2bd82b573d",
   "metadata": {},
   "source": [
    "# 2.0 Train-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f07df2f-44c3-4347-a7ed-8b6716a16870",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(df, test_size=0.2, random_state=42, stratify=df['overall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5e3f54-6372-4f93-9b28-b07679f57fb3",
   "metadata": {},
   "source": [
    "# 3.0 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50408025-a31d-43b6-977c-960d0212c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35163ca4-6103-4a39-829f-333fb3b6a131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a56be76f-89a3-443b-8f84-9aec1ce699ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m             trainable_model_params \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainable model parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainable_model_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mall model parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_model_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mpercentage of trainable model parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mtrainable_model_params\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mall_model_params\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(print_number_of_trainable_model_parameters(\u001b[43mmodel\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# def print_number_of_trainable_model_parameters(model):\n",
    "#     trainable_model_params = 0\n",
    "#     all_model_params = 0\n",
    "#     for _, param in model.named_parameters():\n",
    "#         all_model_params += param.numel()\n",
    "#         if param.requires_grad:\n",
    "#             trainable_model_params += param.numel()\n",
    "#     return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "# print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e07504-3c60-4f6b-a777-03c3957158c9",
   "metadata": {},
   "source": [
    "# Test model with One-Shot(GPT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad0ad83-bb02-4c56-bf48-34788a62472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "# model = GPT2LMHeadModel.from_pretrained('gpt2-medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17d2d173-fc6e-4ade-a617-04cead2f6704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Analyze the sentiment of the following review.\n",
      "\n",
      "I'm not sure how I did it, but miraculously I was able to attach this assembly to the back of my 55\" LG.  Fortunately, this thing was meant to adapt to nearly unlimited orientations and configurations, so after a lot of finagling, I was able to position the arms so that they did not interfere with my power plugs or HDMI cable.\n",
      "\n",
      "I'm hedging my rating since the product's directions did not mention that it would not work with my TV, and due to the effort required to get it to do so.\n",
      "\n",
      "Sentiment:\n",
      "\n",
      "Positive\n",
      "\n",
      "\n",
      "Analyse the sentiment of the following review.\n",
      "\n",
      "Bought it to hang my 43\" Samsung Plasma. I really like the 24\" reach. Lots of flexibility. very strong. Been using it for over half the year and hasn't shown signs of sag.\n",
      "\n",
      "Only problem I have was that the mounting plate blocked the power cord from the TV! Therefore I had to plug the cord (with some jigging around and loosening of screws) in first before mounting. One star off for this oddity. Or maybe it's a Samsung thing?\n",
      "\n",
      "Sentiment:\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SENTIMENT:\n",
      "Positive\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "\n",
      "Analyze the sentiment of the following review.\n",
      "\n",
      "I'm not sure how I did it, but miraculously I was able to attach this assembly to the back of my 55\" LG.  Fortunately, this thing was meant to adapt to nearly unlimited orientations and configurations, so after a lot of finagling, I was able to position the arms so that they did not interfere with my power plugs or HDMI cable.\n",
      "\n",
      "I'm hedging my rating since the product's directions did not mention that it would not work with my TV, and due to the effort required to get it to do so.\n",
      "\n",
      "Sentiment:\n",
      "\n",
      "Positive\n",
      "\n",
      "\n",
      "Analyse the sentiment of the following review.\n",
      "\n",
      "Bought it to hang my 43\" Samsung Plasma. I really like the 24\" reach. Lots of flexibility. very strong. Been using it for over half the year and hasn't shown signs of sag.\n",
      "\n",
      "Only problem I have was that the mounting plate blocked the power cord from the TV! Therefore I had to plug the cord (with some jigging around and loosening of screws) in first before mounting. One star off for this oddity. Or maybe it's a Samsung thing?\n",
      "\n",
      "Sentiment:\n",
      "\n",
      "\n",
      "Negative\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# index = 500\n",
    "# index_example = 400\n",
    "\n",
    "# review = train['reviewText'][index]\n",
    "# sentiment = train['overall'][index]\n",
    "\n",
    "# review_example = train['reviewText'][index_example]\n",
    "# sentiment_example = train['overall'][index_example]\n",
    "\n",
    "# prompt = f\"\"\"\n",
    "# Analyze the sentiment of the following review.\n",
    "\n",
    "# {review_example}\n",
    "\n",
    "# Sentiment:\n",
    "\n",
    "# {sentiment_example}\n",
    "\n",
    "\n",
    "# Analyse the sentiment of the following review.\n",
    "\n",
    "# {review}\n",
    "\n",
    "# Sentiment:\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# inputs = tokenizer(prompt, return_tensors='pt', truncation=True, max_length=512)\n",
    "# output = tokenizer.decode(\n",
    "#     model.generate(\n",
    "#         inputs['input_ids'],\n",
    "#         max_length=512,\n",
    "#         num_return_sequences=1,\n",
    "#         no_repeat_ngram_size=2,\n",
    "#         top_k=50,\n",
    "#         top_p=0.95,\n",
    "#         temperature=0.7\n",
    "#     )[0],\n",
    "#     skip_special_tokens=True\n",
    "# )\n",
    "\n",
    "# dash_line = '-'.join('' for x in range(100))\n",
    "# print(dash_line)\n",
    "\n",
    "# print(f'INPUT PROMPT:\\n{prompt}')\n",
    "# print(dash_line)\n",
    "# print(f'BASELINE HUMAN SENTIMENT:\\n{sentiment}\\n')\n",
    "# print(dash_line)\n",
    "# print(f'MODEL GENERATION - One SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dbc39c-19c7-4e04-882b-a27d5e37fe6b",
   "metadata": {},
   "source": [
    "# Zero Shot with DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55038ab8-eb7c-419b-b2c3-5a0ba09435b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Predicted Sentiment: Positive\n",
      "INPUT PROMPT:\n",
      "Bought it to hang my 43\" Samsung Plasma. I really like the 24\" reach. Lots of flexibility. very strong. Been using it for over half the year and hasn't shown signs of sag.\n",
      "\n",
      "Only problem I have was that the mounting plate blocked the power cord from the TV! Therefore I had to plug the cord (with some jigging around and loosening of screws) in first before mounting. One star off for this oddity. Or maybe it's a Samsung thing?\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SENTIMENT:\n",
      "Positive\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "index = 500\n",
    "\n",
    "review = train['reviewText'][index]\n",
    "sentiment = train['overall'][index]\n",
    "\n",
    "inputs = tokenizer(review, return_tensors='pt', truncation=True, max_length=512, padding='max_length')\n",
    "\n",
    "# Obter a previsão\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "    predicted_label = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "print(predicted_label)\n",
    "\n",
    "sentiment_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "predicted_sentiment = sentiment_map[predicted_label]\n",
    "\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n",
    "\n",
    "print(f'INPUT PROMPT:\\n{review}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SENTIMENT:\\n{sentiment}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{predicted_sentiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b70938d-87f3-4138-a4c5-7cb4735ffda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edilson07/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 3 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 59\u001b[0m\n\u001b[1;32m     36\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     37\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     38\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     52\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     53\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     54\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     55\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     56\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_dataset\n\u001b[1;32m     57\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# 4. Validação\u001b[39;00m\n\u001b[1;32m     62\u001b[0m results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/transformers/trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1630\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1631\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1632\u001b[0m )\n\u001b[0;32m-> 1633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/transformers/trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1900\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1902\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1905\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1906\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1907\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1908\u001b[0m ):\n\u001b[1;32m   1909\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1910\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/transformers/trainer.py:2645\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2645\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2648\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/transformers/trainer.py:2677\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2676\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2677\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2678\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:797\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    796\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m--> 797\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    799\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/sentiment_analysis/lib/python3.10/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 3 is out of bounds."
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, Trainer, TrainingArguments\n",
    "\n",
    "# 1. Mapear sentimentos para IDs numéricos\n",
    "sentiment_id_map = {\n",
    "    'Negative': 0,\n",
    "    'Neutral': 1,\n",
    "    'Positive': 2,\n",
    "    'Very Positive': 3\n",
    "}\n",
    "\n",
    "train['sentiment_id'] = train['overall'].map(sentiment_id_map)\n",
    "validation['sentiment_id'] = validation['overall'].map(sentiment_id_map)\n",
    "\n",
    "# 2. Tokenizar os dados\n",
    "train_encodings = tokenizer(list(train['reviewText']), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(list(validation['reviewText']), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Preparar os datasets no formato do Hugging Face\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SentimentDataset(train_encodings, list(train['sentiment_id']))\n",
    "val_dataset = SentimentDataset(val_encodings, list(validation['sentiment_id']))\n",
    "\n",
    "# 3. Treinar o modelo\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=500,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    output_dir='./results',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 4. Validação\n",
    "results = trainer.evaluate()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3c241-be5b-4b37-8493-37a441c826ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2329cd-668c-4cec-8199-62cadd06c9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cf2562-1699-4806-a660-89d6923f1041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b224f-8654-4217-a64c-9eb1f6b53510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31016e5d-6082-4941-b779-cb144705cc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc986cef-316a-44e6-ac6c-ca6d22630857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
